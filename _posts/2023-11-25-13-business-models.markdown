---
layout: post
title:  "Infinite Thought Leadership"
author: Ivan Bercovich
date:   2023-11-25 01:01:01 -0700
categories:
---
![infinite thought leadership](../assets/infinite-thought-leadership.png)

Traditionally the Turing test will attempt to validate whether the machine is as smart as a person. However, consider what makes you think a piece of text was generated by an LLM. More often than not, it probably comes down to the text sounding too clever, well-written, and very consistent in style.


For now, we can tell when something smells like an LLM, and at least for me, it's off putting. Not because I don't like engaging with Chat GPT-- I love it. But if I assume every piece of thought leadership is an LLM with minimal guidance by the "author", then why would I read anything you post or, if I do, attribute any credibility to the author? 


What is the alternative though? Will 140 characters actually increase in prominence as a format? Will we have to record more videos with some sort of anti-generative verification? (I hope not, I hate recording videos) Will there be a renaissance of in-person events, or at least virtual+live? I want to know what all of you have to say, but I don't want to deal with everyone becoming a cheap thought leader. 


The reality is that each of us probably has very few sufficiently unique and interesting ideas. How do we focus on that?