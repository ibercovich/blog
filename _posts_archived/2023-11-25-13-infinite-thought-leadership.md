---
layout: post
title: "Infinite Thought Leadership"
author: Ivan Bercovich
date: 2023-11-25 01:01:01 -0700
categories:
---

Traditionally, the Turing test attempts to validate whether the machine is as smart as a person. However, consider what makes you think a piece of text was generated by an LLM. More often than not, it probably comes down to the text sounding too clever, well-written, and very consistent in style.

For now, we can tell when something smells like an LLM, and at least for me, it's off-putting. If every piece of thought leadership composed by an LLM with minimal guidance by the "author," then why would I read anything you post or, if I do, attribute any credibility to the author?

What is the alternative? Will 140 characters actually increase in prominence as a format? Will we have to record more videos with some sort of anti-generative verification? (I hope not; I prefer the written word.) Will there be a renaissance of in-person events? I want to know what thoughtful people have to say, but I don't want to deal with everyone becoming a cheap thought leader.

The reality is that each of us probably has few sufficiently unique and interesting ideas. How do we focus on that?
